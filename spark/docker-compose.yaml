services:
  spark-master:
    build:
      context: ./
      dockerfile: ./Dockerfile
    container_name: "spark-master"
    ports:
      - "7077:7077"  # Spark master port
      - "8082:8080"  # Spark master web UI port
    expose: 
      - "7077"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_EXTRA_CLASSPATH=/root/.ivy2/jars/*
    volumes:
      - ./conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
      - /home/hungfnguyen/data_engineer/projects/bigdata-docker-setup/hadoop/config-hadoop/master/config/core-site.xml:/opt/bitnami/spark/conf/core-site.xml
      - /home/hungfnguyen/data_engineer/projects/bigdata-docker-setup/hadoop/config-hadoop/master/config/hdfs-site.xml:/opt/bitnami/spark/conf/hdfs-site.xml
      #- ./gmm:/opt/spark-apps
    networks:
      - data_network

  spark-worker-1:
    image: docker.io/bitnami/spark:3.3.2
    container_name: "spark-worker-1"
    env_file:
      - ../.env
    depends_on:
      - spark-master
    volumes:
      - /home/hungfnguyen/data_engineer/projects/bigdata-docker-setup/hadoop/config-hadoop/master/config/core-site.xml:/opt/bitnami/spark/conf/core-site.xml
      - /home/hungfnguyen/data_engineer/projects/bigdata-docker-setup/hadoop/config-hadoop/master/config/hdfs-site.xml:/opt/bitnami/spark/conf/hdfs-site.xml
    networks:
      - data_network
    mem_limit: 1000m
    environment:
      - SPARK_EXTRA_CLASSPATH=/root/.ivy2/jars/*

  mariadb:
    image: mariadb:10.5.16
    container_name: mariadb
    volumes:
      - ./mariadb:/var/lib/mysql
    ports:
      - "3309:3306"
    env_file:
      - ../.env
    networks:
      - data_network
  
  hive-metastore:
    container_name: hive-metastore
    hostname: hive-metastore
    image: "bitsondatadev/hive-metastore:latest"
    entrypoint: /entrypoint.sh
    ports:
      - "9083:9083"
    volumes:
      - ./hive-metastore/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    environment:
      METASTORE_DB_HOSTNAME: mariadb
    networks:
      - data_network
    depends_on:
      - mariadb

  spark-thrift-server:
    build:
      context: ./
      dockerfile: ./Dockerfile
    container_name: "spark-thrift-server"
    restart: always
    depends_on:
      - spark-master
      - hive-metastore
    ports:
      - "4041:4040"
      - "10000:10000"
    command: sh -c "
      sleep 10 && ./sbin/start-thriftserver.sh --driver-java-options '-Dhive.metastore.uris=thrift://hive-metastore:9083' --master spark://spark-master:7077 --executor-memory 1G --total-executor-cores 1 --driver-memory 1G"
    volumes:
      - ./conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./conf/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    networks:
      - data_network
  
  spark-notebook:
    build: 
      context: ../spark-notebook
      dockerfile: ./Dockerfile
    container_name: "spark-notebook"
    user: root
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - GRANT_SUDO=yes
    volumes:
      - ./notebooks:/home/jovyan/work  # Mount thư mục chứa notebook
      - ../data:/home/jovyan/data      # Mount thư mục chứa dữ liệu nếu cần
      - ./spark-notebook/conf/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
    ports:
      - "8890:8888"
      - "4040:4040"
    networks:
      - data_network


networks:
  data_network:
    driver: bridge
    name: data_network
    external: true

volumes:
  mariadb: {}